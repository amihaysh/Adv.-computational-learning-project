{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utCdmiYTz9uu"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import math\n",
        "import collections\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from decimal import Decimal\n",
        "\n",
        "DEFAULT_VELOCITY_BINS = np.linspace(0, 128, 8+1, dtype=np.int32)\n",
        "BestQuantizationMatch = collections.namedtuple('BestQuantizationMatch',\n",
        "    ['error', 'tick', 'match', 'signedError', 'divisor'])\n",
        "\n",
        "class AlignDataProcessor:\n",
        "    \"\"\"\n",
        "    Data preprocessing based on alignment results.\n",
        "    \"\"\"\n",
        "    def __init__(self, args):\n",
        "        self.df = pd.read_csv(args.path_to_dataset_csv, header=0)\n",
        "        self.isSlice = args.isSlice\n",
        "        self.isFull = args.isFull\n",
        "        self.isOverlap = args.isOverlap\n",
        "        self.savepath = args.path_to_save\n",
        "        self.random_state = args.random_state\n",
        "        self.max_len = args.max_len\n",
        "        self.slice_len = args.slice_len\n",
        "        self.align_files = args.data_folder + self.df[args.align_result_column]\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(input):\n",
        "        return (input - np.mean(input)) / np.std(input)\n",
        "\n",
        "    @staticmethod\n",
        "    def pad_or_cut_sequence(seq, require_len):\n",
        "        if len(seq) >= require_len:\n",
        "            return seq[0:require_len]\n",
        "        else:\n",
        "            return np.concatenate([seq, np.zeros((require_len-len(FEATURES_LIST)))])\n",
        "\n",
        "    @staticmethod\n",
        "    def add_to_list(element, times, target_list):\n",
        "        target_list += [element for i in range(times)]\n",
        "        return target_list\n",
        "\n",
        "    def process(self):\n",
        "        \"\"\"\n",
        "        Process all performances in the dataset.\n",
        "        \"\"\"\n",
        "        x = []\n",
        "        y = []\n",
        "        splits = []\n",
        "\n",
        "        for idx, row in tqdm(self.df.iterrows(), total=self.df.shape[0]):\n",
        "            seq = np.random.rand(self.max_len, len(FEATURES_LIST))  # Dummy feature extraction\n",
        "            x.append(self.pad_or_cut_sequence(seq, self.max_len))\n",
        "            y.append(row['artist_id'])\n",
        "            splits.append(row['type'])\n",
        "\n",
        "        self.x = np.asarray(x)\n",
        "        self.y = np.asarray(y)\n",
        "        self.splits = np.asarray(splits)\n",
        "        print(\"Total performances (in segments):\" + str(self.x.shape))\n",
        "\n",
        "        # Apply data augmentation\n",
        "        self.x, self.y, self.splits = self.augment_data(self.x, self.y, self.splits)\n",
        "\n",
        "    def save(self):\n",
        "        np.savez(self.savepath, train_x=self.x, train_y=self.y, splits=self.splits)\n",
        "\n",
        "    def augment_data(self, x, y, splits, num_augment=1, pitch_index=0, velocity_index=3):\n",
        "        \"\"\"\n",
        "        Data augmentation function that duplicates existing sequences\n",
        "        and applies random pitch and velocity shifts.\n",
        "        \"\"\"\n",
        "        augmented_x = []\n",
        "        augmented_y = []\n",
        "        augmented_splits = []\n",
        "\n",
        "        for i in range(len(x)):\n",
        "            original_seq = x[i]\n",
        "            original_label = y[i]\n",
        "            original_split = splits[i]\n",
        "\n",
        "            for _ in range(num_augment):\n",
        "                new_seq = np.copy(original_seq)\n",
        "                pitch_shift = np.random.randint(-2, 3)\n",
        "                velocity_scale = 0.8 + 0.4 * np.random.rand()\n",
        "\n",
        "                new_seq[:, pitch_index] += pitch_shift\n",
        "                new_seq[:, velocity_index] = np.clip(new_seq[:, velocity_index] * velocity_scale, 0, 127)\n",
        "\n",
        "                augmented_x.append(new_seq)\n",
        "                augmented_y.append(original_label)\n",
        "                augmented_splits.append(original_split)\n",
        "\n",
        "        return np.array(augmented_x), np.array(augmented_y), np.array(augmented_splits)\n"
      ]
    }
  ]
}